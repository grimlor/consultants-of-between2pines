# Jared Pines
ðŸ“ Greater Seattle Area  
ðŸ“± [(407) 620-3976](tel:407-620-3976)  
ðŸ“§ [pinesjared@gmail.com](mailto:pinesjared@gmail.com)  
ðŸ’¼ Junior Data Engineer | Python â€¢ Spark â€¢ Snowflake â€¢ Databricks

---

## Summary

Detail-oriented and motivated Data Engineer with hands-on experience delivering data pipelines and orchestration systems using modern tools like **Databricks**, **Airflow**, and **Snowflake**. Skilled in **Python**, **Java**, **SQL**, and **Spark**, with exposure to cloud-native data engineering workflows. Passionate about using data to drive clarity and action. Seeking opportunities to contribute to scalable, high-quality data systems in a team-oriented environment.

---

## Technical Skills

**Languages**: Python, Java, SQL, Bash/Zsh  
**Tools & Platforms**: Databricks, Airflow, Snowflake, PostgreSQL, Git, Docker (intro), VSCode  
**Data Engineering**: ETL/ELT, Spark (PySpark), Pandas, Polars, REST API ingestion, Data Warehousing  
**Workflow & Orchestration**: Apache Airflow (DAGs), Git version control  
**Data Visualization**: Snowflake Dashboards, Excel, basic matplotlib  
**Operating Systems**: Windows, Linux, MacOS  

---

## Experience

### Between2Pines Consulting â€” *Data Engineer (Consultant in residence)*
**Feb 2025 â€“ Present | Remote (metro-Seattle-based)**  
*Working under the mentorship of senior consultants on client-facing and internal data projects.*

- Designed and built **automated ETL pipelines** in Python and SQL for real-world data ingestion, transformation, and loading into **Snowflake**.
- Created and maintained **Airflow DAGs** to orchestrate multi-stage workflows, supporting modular and testable code deployments.
- Cleaned and normalized datasets using **Pandas**, Spark (**PySpark**), and SQL, improving data quality for analytical use.
- Upgraded Databricks compute environments for **scalable Spark workloads**, tuning performance for daily pipeline runs.
- Collaborated on Git-based version-controlled development and basic containerization practices.

**Example Project**:  
Refactored a legacy data cleaning process into a parameterized Spark job, cutting execution time from 25 minutes to 4 minutes for a sample dataset. 

---

## Education

### University of Washington Tacoma  
**Bachelor of Arts in Computer Science**  
Sep 2021 â€“ Jun 2023

### Skagit Valley College  
**Associateâ€™s Degree, Computer Science**  
Jul 2019 â€“ Jun 2021

---

## Certifications

- [PCEP-30-02] Certified Entry-Level Python Programmer  
- Microsoft Office Specialist â€“ Word 2016 & PowerPoint 2016  
- Phi Theta Kappa Honor Society

---

## GitHub & Projects

*Coming Soon: Public portfolio of reusable pipelines, cloud warehouse connectors, and Airflow orchestrated jobs.*

> ðŸš§ GitHub link to be added once portfolio projects are published.

---

## Keywords for Recruiters (ATS Optimization)
Python, SQL, Spark, Databricks, Snowflake, Airflow, Data Engineering, ETL, Git, Data Pipelines, Orchestration, REST APIs, Pandas, Polars, dbt (learning), Docker (basic), Bash, Zsh

---

## Availability

Available for full-time, hybrid, or remote roles nationwide. Open to internships, contract-to-hire, and early-career development programs.
